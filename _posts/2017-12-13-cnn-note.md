---
layout: post
title: CNNæµç¨‹ç®€å•æ¢³ç†
data: 2017-12-13
author: Nicholas Huang
header-img: 
categories: CNN
tags:
    - CNN
    - Deep Learning
--- 
# CNNæµç¨‹ç®€å•æ¢³ç†
æˆ‘ç†è§£çš„CNNå°±æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿäººè„‘è®¤çŸ¥çš„ç½‘ç»œï¼Œé€šè¿‡filterï¼ˆæˆ–è€…å«kernelï¼‰è¯†åˆ«æ•°æ®ç‰¹å¾â€”â€”ç±»æ¯”äººçœ¼å¯¹æ•°æ®ç”Ÿæˆç”µä¿¡å·ï¼Œå¯¹ç‰¹å¾åˆ©ç”¨å„ç§æ•°å­¦è¿ç®—ä»¥å®ŒæˆåŒºåˆ†â€”â€”æ¨¡æ‹Ÿäººè„‘ä¸­çš„ç¥ç»å…ƒå¯¹ç”µä¿¡å·çš„ååº”ï¼Œå¤šæ¬¡é‡å¤è¿™ä¸ªè¿‡ç¨‹ä»¥è¾¾åˆ°è¯†åˆ«ã€è®¤çŸ¥çš„ç›®çš„ã€‚

<!-- CNNæ•´ä½“å›¾ -->
å…ˆç”¨å‡ å¼ å›¾æ¥æ¯”è¾ƒå½¢è±¡çš„è§‚å¯Ÿä¸‹CNNçš„æµç¨‹ï¼š

![CNN1](https://www.mathworks.com/content/mathworks/www/en/discovery/convolutional-neural-network/jcr:content/mainParsys/image_copy.adapt.full.high.jpg/1492406018870.jpg)

è¯¥å›¾æ¥æºäº[pic source1](https://www.mathworks.com/content/mathworks/www/en/discovery/convolutional-neural-network/jcr:content/mainParsys/image_copy.adapt.full.high.jpg/1492406018870.jpg)

åœ¨è¿™å¼ å›¾ä¸Šï¼Œå¯ä»¥çœ‹åˆ°å·¦è¾¹çš„ä¸€å¼ è½¦çš„å›¾ç‰‡è¾“å…¥åˆ°CNNåï¼Œå³è¾¹ä¼šå‡ºæ¥å¤šä¸ªè¯†åˆ«ç»“æœï¼Œæ¯”å¦‚å°æ±½è½¦(car)ï¼Œå¡è½¦(truck)ï¼Œé¢åŒ…è½¦(van)ï¼Œè‡ªè¡Œè½¦(bicycle)ç­‰ï¼Œæ¯ä¸ªç»“æœä¼šå¯¹åº”ä¸€ä¸ª0åˆ°1çš„æ¦‚ç‡ï¼Œæ¦‚ç‡å€¼è¶Šå¤§è¡¨ç¤ºå±äºè¿™ä¸ªç»“æœçš„å¯èƒ½æ€§è¶Šå¤§ã€‚

![CNN2](https://www.researchgate.net/profile/B_Mesman/publication/220785200/figure/fig1/AS:340720692023305@1458245551937/Fig-1-An-Example-CNN-architecture-for-a-handwritten-digit-recognition-task.png)

è¯¥å›¾æ¥æºäº[pic source2](https://www.researchgate.net/profile/B_Mesman/publication/220785200/figure/fig1/AS:340720692023305@1458245551937/Fig-1-An-Example-CNN-architecture-for-a-handwritten-digit-recognition-task.png)

åœ¨è¿™å¼ å›¾ä¸Šï¼Œå½¢è±¡çš„è¡¨ç¤ºäº†ç‰¹å¾å›¾(feature map)ã€‚

é€šè¿‡è¿™ä¸¤å¼ å›¾ï¼Œæˆ‘ä»¬èƒ½å¤Ÿçœ‹å‡ºå…±æ€§çš„ä¸œè¥¿ï¼š
**1.** éƒ½æœ‰å·ç§¯å±‚(convolution layer)ï¼Œå¹¶ä¸”å·ç§¯å±‚ä¼šæœ‰å¤šä¸ªï¼Œå·ç§¯å±‚åŒ…å«ä¸¤ä¸ªæ“ä½œï¼Œå·ç§¯(convolution)å’ŒReLUã€‚
**2.** éƒ½æœ‰æ± åŒ–å±‚(pooling layer or subsampling layer)ï¼Œå®ƒçš„è¾“å…¥å°±æ˜¯å·ç§¯å±‚çš„è¾“å‡ºã€‚ä½†æ˜¯ä¸èƒ½è®¤ä¸ºæ¯ä¸€ä¸ªå·ç§¯å±‚åé¢å°±ä¼šæœ‰ä¸€ä¸ªæ± åŒ–å±‚ï¼Œå¯ä»¥å¤šä¸ªå·ç§¯å±‚åæ¥ä¸€ä¸ªæ± åŒ–å±‚ã€‚
**3.** éƒ½æœ‰å…¨è¿æ¥å±‚(fully connected layer)ï¼Œå®ƒå°±æ˜¯æŠŠå‰é¢è®¡ç®—å‡ºæ¥çš„ç»“æœä¸¤ä¸¤ç›¸ä¹˜ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œåœ¨ç¬¬ä¸€ä¸ªå…¨è¿æ¥å±‚çš„è¾“å…¥å¤„æœ‰ä¸€ä¸ªæ‹‰å¹³(flatten)çš„æ“ä½œï¼Œå®ƒæ˜¯æŠŠåœ¨è¿™å±‚ä¹‹å‰çš„æ± åŒ–å±‚çš„ç»“æœæ‹‰å¹³æˆä¸€ä¸ª[1, N_Classes]ï¼Œå…¶ä¸­N_Classeså°±æ˜¯éœ€è¦è¯†åˆ«çš„æ ‡ç­¾çš„ä¸ªæ•°ã€‚

çœ‹è¿‡äº†CNNçš„å†…éƒ¨ç»“æ„ï¼Œç›¸å½“äºè®¤è¯†äº†CNNçš„â€œç¡¬ä»¶â€æ˜¯æ€æ ·æ„æˆçš„ï¼Œç°åœ¨æˆ‘ä»¬éœ€è¦äº†è§£ä¸‹CNNçš„â€œè½¯ä»¶â€æ˜¯æ€æ ·è¿ä½œçš„ã€‚æ¨è[A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks](https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/)çš„Trainingå°èŠ‚ã€‚ä¸€å¥è¯æ€»ç»“å°±æ˜¯ï¼ŒCNNçš„æ›´æ–°æƒå€¼(weight)çš„è¿‡ç¨‹å«åå‘ä¼ æ’­(backpropagation)ã€‚åå‘ä¼ æ’­ç”±å‰å‘ä¼ é€’(forward pass)ã€æŸå¤±å‡½æ•°(loss function)ã€åå‘ä¼ é€’(backward pass)å’Œæƒå€¼æ›´æ–°(weight update)å››éƒ¨åˆ†ç»„æˆï¼Œ[Principles of training multi-layer neural network using backpropagation](http://galaxy.agh.edu.pl/~vlsi/AI/backp_t_en/backprop.html)ç”¨å›¾è¡¨ç¤ºäº†æ•´ä¸ªè¿‡ç¨‹ã€‚åå‘ä¼ æ’­ç®—æ³•çš„åŸç†è¯·çœ‹[ã€Šdeep learningã€‹](http://www.deeplearningbook.org/)6.5èŠ‚ã€‚åå‘ä¼ æ’­ç®—æ³•ä¸»è¦æ˜¯ç”¨äºè®¡ç®—æ¢¯åº¦ï¼Œè€Œå¦ä¸€ç§ç®—æ³•ï¼Œæ¯”å¦‚éšæœºæ¢¯åº¦ä¸‹é™(SGD)ã€Adamï¼Œç”¨è¯¥æ¢¯åº¦æ¥è¿›è¡Œå­¦ä¹ ã€‚

ä»¥ä¸‹å‡ç”¨Googleçš„tensorflowæ¡†æ¶åšä»£ç æ¼”ç¤ºã€‚
## å‰å‘ä¼ é€’(forward pass)
### å·ç§¯å±‚ï¼ˆConvolutioanl Layer)
#### å·ç§¯è¿ç®—
##### ä»€ä¹ˆæ˜¯å·ç§¯
å·ç§¯çš„[wiki](https://en.wikipedia.org/wiki/Convolution)ï¼Œæˆ‘æ‰¾åˆ°çš„ä¸€ä¸ªæ¯”è¾ƒå¥½çš„è¯´æ˜[çŸ¥ä¹](https://www.zhihu.com/question/22298352)ã€‚æˆ‘ä¸ªäººè‡ªå·±æ€»ç»“çš„è¯ï¼Œå°±æ˜¯å¯¹ä¸¤ä¸ªåŒç»´çŸ©é˜µåšç‚¹ç§¯ä¹‹åçš„æ–°çŸ©é˜µä¸­çš„æ¯ä¸ªå€¼æ±‚å’Œã€‚æ¯ä¸ªå’Œå°±æ˜¯ä¸€ä¸ªç‰¹å¾ï¼ˆfeatureï¼‰ï¼Œè¿™ä¹Ÿå°±æ˜¯è¿‡æ»¤çš„è¿‡ç¨‹ã€‚

å…¶å®è¿™ç§é€šè¿‡æå–ç‰¹å¾è€Œè¯†åˆ«æ•´ä½“çš„è¿‡ç¨‹ï¼Œå¤ä»£å°±å·²ç»å‡ºç°äº†ï¼Œè€Œä¸”æˆ‘ä»¬è¿˜å­¦ä¹ äº†ç›¸å…³è¯¾æ–‡çš„ï¼Œå³ç›²äººæ‘¸è±¡ã€‚
æ¯ä¸ªç›²äººåªæ„ŸçŸ¥äº†è±¡çš„ä¸€éƒ¨åˆ†ï¼ŒæŠŠä»–ä»¬æ‰€æœ‰çš„æ„è§åˆå¹¶èµ·æ¥ï¼Œå°±å½¢æˆäº†ä¸€ä¸ªå®Œæ•´çš„è±¡ã€‚
å¦‚æœä¸Šé¢è¿™ä¸ªä¸¾ä¾‹è¿˜ä¸å¤Ÿæ¸…æ¥šçš„è¯ï¼Œé‚£æˆ‘å†ä¸¾ä¸ªä¾‹å­ã€‚
å‡å¦‚æˆ‘ä»¬åœ¨ä¸€ä¸ªç»å¯¹é»‘æš—çš„æˆ¿é—´ï¼Œæˆ‘ä»¬åœ¨è¿™ä¸ªæˆ¿é—´åœ°é¢çš„ä¸­å¿ƒï¼Œå³æ‰‹æœ‰ä¸€ä¸ªæ‰‹ç”µç­’ï¼Œé¢å¯¹ç€ä¸€ä¸ªæœ‰è’™å¨œä¸½èç”»é¢çš„å¢™å£ã€‚å½“æˆ‘ä»¬ä¸¾èµ·å³æ‰‹çš„æ‰‹ç”µç­’ï¼Œä»ä¸Šå¾€ä¸‹ï¼Œä»å·¦è‡³å³ï¼Œä¾æ¬¡ç…§å°„ï¼Œé‚£ä¹ˆä»æ¯ä¸€æ¬¡çš„ç…§å°„ä¸­å°±çœ‹åˆ°äº†ä¸€å°å—åŒºåŸŸï¼Œå½“æ‰‹ç”µç­’ç…§åˆ°å³ä¸‹è§’çš„æ—¶å€™ï¼Œæ•´ä¸ªè¿‡ç¨‹å®Œæ¯•ï¼Œè€Œæˆ‘ä»¬ä¹Ÿå½¢æˆäº†å¯¹è’™å¨œä¸½èçš„æ•´ä½“è®¤çŸ¥ã€‚

å·ç§¯è¿ç®—çš„æ ¸å¿ƒæ˜¯filterï¼Œåˆç§°kernelã€‚æ ¹æ®åå­—æˆ‘ä»¬èƒ½å¤ŸçŒœæµ‹å‡ºï¼Œè¿™ä¸ªæ ¸å¿ƒå°±æ˜¯ä¸€ä¸ªè¿‡æ»¤å™¨ï¼Œä»–æŠŠç‰¹å¾è¿‡æ»¤å‡ºæ¥ï¼Œç„¶åè¾“å…¥åˆ°åç»­çš„ç½‘ç»œæµç¨‹ä¸­ã€‚
é‚£ä¹ˆæ€æ ·å®ç°è¿‡æ»¤ï¼Œæ€æ ·å¯¹è¿‡æ»¤çš„ç»“æœåšåŒºåˆ†å‘¢ï¼Ÿè¿™å°±æ˜¯æœ¬å°èŠ‚å’Œåé¢çš„ReLUã€æ± åŒ–å±‚æ‰€æ¶‰åŠçš„ã€‚
##### å·ç§¯çš„å®ç°
ç”¨ä¸€ä¸ªå›¾æ¥å½¢è±¡çš„è¯´æ˜ï¼š

![pic](https://raw.githubusercontent.com/h312903294/MarkdownPicRep/master/convSobel.gif)

è¯¥å›¾æ¥æºäº[Convolutional Neural Networks - Basics](https://mlnotebook.github.io/post/CNN1/)

åœ¨tensorflowä¸­ï¼Œå…³äºconvolutionçš„è¯´æ˜åœ¨[è¿™é‡Œ](https://www.tensorflow.org/api_guides/python/nn#Convolution)
åœ¨tensorflowä¸­ï¼Œæ‰§è¡Œå·ç§¯è¿ç®—çš„apiæ˜¯[tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)ã€‚åœ¨è¯¥apiä¸­ï¼Œæˆ‘ä»¬éœ€è¦æ³¨æ„çš„æ˜¯ä»¥ä¸‹å‡ ä¸ªå‚æ•°ï¼š

**1. input**â€”â€”ç›¸å½“äºä¸Šé¢å°é»‘å±‹ä¸¾ä¾‹ä¸­çš„é‚£å¹…è’™å¨œä¸½èçš„ç”»â€”â€”è¯¥å˜é‡æ˜¯ä¸€ä¸ª4é˜¶çš„å¼ é‡ï¼ˆa 4D tensorï¼‰ï¼Œshapeè¡¨ç¤ºä¸º[batch,in_height,in_width,in_channels]ã€‚å…¶ä¸­batchè¡¨ç¤ºæ¯æ¬¡è®­ç»ƒçš„æ—¶å€™è¾“å…¥ä¸€æ‰¹å›¾ç‰‡çš„å¤§å°ï¼Œä¸€èˆ¬å¡«-1ï¼Œè¡¨ç¤ºè¿è¡Œæ—¶ç¡®å®šã€‚in_heigthå’Œin_widthè¡¨ç¤ºinputçš„é«˜å’Œå®½ã€‚in_channelsè¡¨ç¤ºinputçš„é€šé“ä¸ªæ•°ï¼Œä»¥å›¾ç‰‡ä¸¾ä¾‹ï¼Œæˆ‘ä»¬çŸ¥é“è‰²å½©æœ‰[ä¸‰åŸè‰²RGB](https://zh.wikipedia.org/wiki/%E5%8E%9F%E8%89%B2)ï¼Œé‚£ä¹ˆç”¨çŸ©é˜µæ¥è¡¨ç¤ºä¸€ä¸ªå›¾ç‰‡çš„æ—¶å€™ï¼Œæ¯ç§é¢œè‰²éƒ½è¦å¯¹åº”ä¸€ä¸ªçŸ©é˜µï¼Œæ‰€ä»¥ä¸€å¼ å›¾ç‰‡æœ‰ä¸‰ä¸ªçŸ©é˜µï¼Œè¿™é‡Œå°±å¯ä»¥æŠŠçŸ©é˜µå’Œé€šé“ç­‰ä»·èµ·æ¥ã€‚æ‰€ä»¥å¦‚æœä¸€ä¸ªinputæ•°æ®éœ€è¦å¤šä¸ªé€šé“ï¼ˆçŸ©é˜µï¼‰æ¥è¡¨ç¤ºçš„è¯ï¼Œæˆ‘ä»¬éœ€è¦é€šè¿‡æŒ‡å®šin_channelsçš„å€¼æ¥è¡¨ç¤ºé€šé“çš„ä¸ªæ•°ï¼Œä»¥ä¿è¯åç»­å„ç§è¿ç®—çš„æ­£ç¡®ã€‚

**2. filter**â€”â€”ç›¸å½“äºä¸Šé¢æåˆ°çš„æ‰‹ç”µç­’â€”â€”æ˜¯ä¸€ä¸ª4é˜¶çš„å¼ é‡ï¼ˆa 4D tensorï¼‰ï¼Œshapeè¡¨ç¤ºä¸º[height,width,in_channels,out_channels]ï¼Œå…¶ä¸­heightå’Œwidthçš„å€¼å»ºè®®æ˜¯å¥‡æ•°ä¸”ç›¸ç­‰ï¼Œä¹‹æ‰€ä»¥é€‰æ‹©å¥‡æ•°ï¼Œå¯ä»¥å‚è€ƒ[Quora](https://www.reddit.com/r/MachineLearning/comments/36rd91/any_reason_behind_the_fact_that_the_filter_size/)å’Œ[çŸ¥ä¹](https://www.zhihu.com/question/51603070)ã€‚æˆ‘ä¸ªäººçš„ç†è§£å°±æ˜¯ï¼Œå¦‚æœä½¿ç”¨å¥‡æ•°ï¼Œfilterä¼šæœ‰ä¸€ä¸ªä¸­å¿ƒç‚¹ï¼Œè¿™æ ·çš„è¯filteråœ¨inputä¸Šçš„ç§»åŠ¨ä¼šä»¥ä¸­å¿ƒç‚¹ä¸ºåŸºå‡†ï¼Œå¦å¤–å°±æ˜¯åœ¨inputçš„è¾¹ç¼˜è¡¥é›¶çš„è¯æœ‰ä¸€ä¸ªä¸­å¿ƒç‚¹çš„è¯å¯ä»¥å¯¹ç§°çš„è¡¥é›¶ã€‚

**3. strides**â€”â€”ç¡®å®šfilteræ¯æ¬¡ç§»åŠ¨çš„æ­¥è¿›ï¼Œå°±æ˜¯ä¸Šé¢ä¾‹å­ä¸­ç§»åŠ¨æ‰‹ç”µç­’çš„æ–¹å¼ï¼Œæ˜¯æ¯æ¬¡éƒ½å’Œä¹‹å‰ç…§å°„çš„åŒºåŸŸè¦†ç›–ä¸€éƒ¨åˆ†å‘¢ï¼Œè¿˜æ˜¯ç›¸åˆ‡å‘¢ç­‰ç­‰â€”â€”è¯¥å˜é‡ä¹Ÿæ˜¯ä¸€ä¸ª4é˜¶çš„å¼ é‡(a 4D tensor)ï¼Œshapeè¡¨ç¤ºä¸º[1, stride, stride, 1]ï¼ŒGoogleç»™çš„è§£é‡Šå¦‚ä¸‹ï¼š
> Must have strides[0] = strides[3] = 1. For the most common case of the same horizontal and vertices strides

è‡³äºstrides[1]å’Œstrides[2]çš„å…·ä½“å¤§å°ï¼Œå¯ä»¥å‚è€ƒå·²æœ‰çš„modelï¼Œç„¶åå¤šç‚¼é‡‘å‡ æ¬¡ï¼ŒğŸ™‚

**4. padding**â€”â€”è¿™æ˜¯ä¸ºäº†è§£å†³æ‰‹ç”µç­’ç…§å°„åˆ°è’™å¨œä¸½èçš„å››æ¡è¾¹çš„æ—¶å€™ï¼Œè¾¹ç•Œå¤–é¢é‚£äº›æ²¡æœ‰é¢œæ–™çš„åœ°æ–¹æ€ä¹ˆåŠçš„é—®é¢˜â€”â€”å®ƒåªæœ‰ä¸¤ä¸ªå€¼ï¼Œ"SAME", "VALID"ã€‚è¿™ä¸¤ä¸ªå€¼å¯¹åº”çš„æ“ä½œåœ¨[è¿™é‡Œ](https://www.tensorflow.org/api_guides/python/nn#Convolution)ï¼Œä¸€ç¯‡[csdnçš„blog](http://blog.csdn.net/lujiandong1/article/details/53728053)ä¹Ÿæ¯”è¾ƒå½¢è±¡çš„è§£é‡Šäº†è¿™ä¸¤ä¸ªå€¼ã€‚

é€šè¿‡ä¸Šé¢çš„æ¢³ç†ï¼Œæˆ‘ä»¬å‘ç°ï¼Œåªæœ‰filteræ˜¯ä¸€ä¸ªä¸èƒ½ç¡®å®šå€¼çš„å˜é‡ï¼Œå®ƒçš„å€¼ä¸æ˜¯äººä¸ºæŒ‡å®šçš„ã€‚
è¿™å°±æ˜¯ä¸ºä»€ä¹ˆDeep Learningä¸­æœ‰ä¸€ä¸ªlearningçš„åŸå› ä¹‹ä¸€ï¼Œå› ä¸ºfilterçš„å€¼çš„æ›´æ–°æ˜¯é€šè¿‡æ•´è¿‡ç½‘ç»œè®­ç»ƒè¿‡ç¨‹ä¸­å­¦ä¹ æ¥çš„ã€‚

ç”±äºä¸Šé¢æåˆ°çš„filterçš„ä¸ç¡®å®šï¼Œæˆ‘ä»¬åªä¼šç»™filterä¸€ä¸ªåˆå§‹åŒ–çš„æ“ä½œï¼Œæ‰§è¡Œè¿™ä¸ªæ“ä½œçš„apiæ˜¯[tf.truncated_normal_initializer](https://www.tensorflow.org/api_docs/python/tf/truncated_normal_initializer)ã€‚å…³äºæˆªæ–­æ­£æ€åˆ†å¸ƒï¼Œ[çŸ¥ä¹](https://www.zhihu.com/question/49923924)çš„è¿™ä¸ªæœ€é«˜ç¥¨è¯´çš„å¾ˆå¥½ï¼Œä¸€å¥è¯å°±æ˜¯åœ¨æŸä¸ªèŒƒå›´å†…åšæ­£æ€åˆ†å¸ƒã€‚ä¸ºä»€ä¹ˆè¦æ­£æ€åˆ†å¸ƒï¼Œå› ä¸ºè¦åŠ å…¥å°‘é‡çš„å™ªå£°æ¥æ‰“ç ´å¯¹ç§°æ€§å’Œé¿å…0æ¢¯åº¦ã€‚å¦‚æœæ˜¯å®Œå…¨éšæœºçš„è¯ï¼Œæˆ‘ä»¬åç»­æ— æ³•é€šè¿‡æ¢¯åº¦ä¸‹é™æ¥æ›´æ–°filterï¼Œä½¿ç”¨æ­£æ€åˆ†å¸ƒï¼Œèƒ½ä¿è¯filterçš„åˆå§‹å€¼æ˜¯åœ¨ä¸€ä¸ªæœ‰é™èŒƒå›´å†…ï¼Œå¹¶ä¸”æ¯”è¾ƒé›†ä¸­ï¼Œå½“åç»­æ¢¯åº¦ä¸‹é™çš„æ—¶å€™ï¼ŒæŒ‰ç…§å‘å¾®åˆ†ç›¸åæ–¹å‘ä¸‹é™çš„è§„åˆ™ï¼Œå°±å¯ä»¥è¿…é€Ÿæ›´æ–°filterã€‚

ä¸€èˆ¬æ¥è¯´ï¼Œæˆ‘ä»¬ä½¿ç”¨tf.truncated_normal_initializerï¼Œåªä¿®æ”¹stddevè¿™ä¸ªå‚æ•°ï¼Œå³[æ ‡å‡†å·®](https://zh.wikipedia.org/wiki/%E6%A8%99%E6%BA%96%E5%B7%AE)ã€‚è¿™å°±æ„å‘³ç€ï¼Œfilterçš„å€¼æ˜¯ä»¥0ä¸ºå‡å€¼çš„ä¸€ä¸ªæˆªæ–­æ­£æ€åˆ†å¸ƒã€‚stddevçš„å–å€¼å¯ä»¥å‚è€ƒå·²æœ‰æ¨¡å‹ï¼Œæˆ‘ä¹ æƒ¯å–0.1ã€‚

é‚£ä¹ˆå·ç§¯çš„æ“ä½œå°±å®Œäº†ï¼Ÿå¹¶æ²¡æœ‰ï¼Œè€Œä¸”åé¢è¿™ä¸ªæ“ä½œä¹Ÿæ˜¯éå¸¸é‡è¦çš„ï¼

å½“æˆ‘ä»¬è°ƒç”¨å®Œtf.nn.conv2dï¼Œéœ€è¦å¯¹ç»“æœåŠ biasesï¼ˆåç½®é¡¹ï¼‰ï¼Œå³ï¼š
$$ Y = \sum (weight * input) + bias $$

biasæ˜¯ä¸€ä¸ªåˆå§‹åŒ–ä¸ºéå¸¸å°çš„æ­£æ•°çš„å¸¸æ•°â€”â€”é€šè¿‡è°ƒç”¨tf.constant_initializerã€‚
å¢åŠ è¿™ä¸ªåç½®é¡¹çš„æ„ä¹‰å¯ä»¥å‚è€ƒ[stackoverfow](https://stackoverflow.com/questions/25792577/is-the-bias-node-necessary-in-very-large-neural-networks)å’Œå¦ä¸€ä¸ª[stackoverflow](https://stackoverflow.com/questions/2480650/role-of-bias-in-neural-networks)ï¼Œåœ¨è¿™ä¸¤ä¸ªé—®é¢˜çš„received answerä¸­éƒ½æåˆ°äº†ä¸€ä¸ªå•è¯ï¼Œshiftã€‚
æˆ‘ä¸ªäººçš„ç†è§£æ˜¯ï¼Œå½“è¿‡æ»¤äº†ä¸€ä¸ªç‰¹å¾å‡ºæ¥ï¼Œä¸ºäº†è®©è¿™ä¸ªç‰¹å¾æ›´åŠ çš„æ³›åŒ–ï¼ˆgeneralizationï¼‰ï¼Œéœ€è¦è°ƒæ•´è¿™ä¸ªç‰¹å¾ä»¥è®©ä»–é€‚é…æ›´å¤§èŒƒå›´å†…çš„å·®å€¼ï¼Œå› æ­¤åŠ ä¸€ä¸ªbiasã€‚ç”¨çº¿æ€§æ–¹ç¨‹$y=f(x)+b$ä¸¾ä¾‹ï¼Œ$y=f(x)+b (b>0)$å¯¹$y=f(x)$åšäº†bå¤§å°çš„å¹³ç§»ï¼Œå¦‚æœä»¤$y=f(x)+b>0$ï¼Œé‚£ä¹ˆç›¸åŒ$y$çš„å–å€¼èŒƒå›´ï¼Œå¾—åˆ°çš„$x$çš„å–å€¼èŒƒå›´æ¯”$y=f(x)>0$å¤§ã€‚

è‡³æ­¤ï¼Œå·ç§¯çš„åŸç†å’Œè¿‡ç¨‹éƒ½æ¢³ç†å®Œæ¯•ï¼Œå®ƒæ˜¯ä¸€ä¸ªCNNèƒ½å·¥ä½œçš„åŸºçŸ³ã€‚
#### ReLU
å…ˆè§£é‡Šä¸€ä¸‹ç¥ç»ç½‘ç»œä¸­æ¿€æ´»å‡½æ•°ï¼ˆactivation functionï¼‰çš„æ¦‚å¿µã€‚æ¿€æ´»å‡½æ•°çš„[wiki](https://en.wikipedia.org/wiki/Activation_function)ç”¨digital networkåšç±»æ¯”ï¼Œ[Understanding Activation Functions in Neural Networks](https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0)ç”¨äººè„‘åšç±»æ¯”ã€‚æˆ‘ä¸ªäººæ€»ç»“ï¼Œä¸€å¥è¯ï¼šOä¸OKï¼Ÿï¼ˆè¯·è‡ªè¡Œè„‘è¡¥å£°éŸ³ï¼‰ã€‚å¦‚æœä¸OKï¼Œé‚£ä¹ˆå°±æ”¾å¼ƒï¼Œå¦‚æœOKï¼Œé‚£ä¹ˆå…ˆç•™ä¸‹è¿™ä¸ªå·ç§¯ç»“æœå†ç­‰å¾…åç»­å¤„ç†ã€‚è¿™ç±»å‡½æ•°é™ä½äº†æ•´ä¸ªç½‘ç»œçš„å¤æ‚åº¦ï¼Œå› ä¸ºä»–å»é™¤äº†ä¸€äº›å·ç§¯ç»“æœã€‚å¦‚æœå‰é¢çš„è‹±æ–‡çœ‹èµ·æ¥æœ‰éš¾åº¦ï¼Œè¿™é‡Œæœ‰ä¸ª[çŸ¥ä¹](https://www.zhihu.com/question/22334626)ä¸Šçš„é—®é¢˜è¿˜æ˜¯èƒ½è§£å†³ä½ çš„ç–‘æƒ‘çš„ã€‚å¦‚æœè¿˜ä¸ç†è§£ï¼Œé‚£ä¹ˆæˆ‘ä»¬ç”¨CNNæ¨¡æ‹Ÿçš„å¯¹è±¡ï¼Œå³äººè„‘åšè¯´æ˜ã€‚æˆ‘ä»¬çŸ¥é“ï¼Œäººè„‘ä¸­çš„ç¥ç»å…ƒæ˜¯é€šè¿‡ç”µä¿¡å·çš„åˆºæ¿€æ¥åšå‡ºååº”çš„ï¼Œæ—¢ç„¶æ˜¯ç”µä¿¡å·é‚£ä¹ˆå°±ä¼šæœ‰ç”µå‹ï¼Œå¦‚æœç”µå‹ä¸å¤Ÿï¼Œåˆºæ¿€ä¸äº†ç¥ç»å…ƒï¼Œé‚£ä¹ˆå¯¹è¿™ä¸ªç”µä¿¡å·å°±ä¼šè¢«æ”¾å¼ƒã€‚å› ä¸ºä½ éƒ½ä¸èƒ½åˆºæ¿€ç¥ç»å…ƒï¼Œé‚£å¯¹äººè„‘æ¥è¯´ä½ å°±æ˜¯è¾£é¸¡ï¼Œæ‰€ä»¥éœ€è¦å»å…¶ç³Ÿç²•ï¼Œç•™å…¶ç²¾åã€‚

ReLUï¼Œæ˜¯Rectified Linear Unitçš„ç®€å†™ï¼Œä¸­æ–‡åçº¿æ€§æ•´æµå‡½æ•°ï¼Œå®ƒçš„[wiki](https://zh.wikipedia.org/wiki/%E7%BA%BF%E6%80%A7%E6%95%B4%E6%B5%81%E5%87%BD%E6%95%B0)ã€‚
å‡½æ•°å½¢å¼$f(x)=max(0,x)$ï¼Œè¿™ä¸ªå‡½æ•°ä¹Ÿæœ‰å‡ ä¸ªå˜ç§ï¼Œåœ¨å®ƒçš„wikiä¸­æœ‰ä»‹ç»ã€‚

ä¸ºä»€ä¹ˆç°åœ¨å¾ˆå¤šé€‰ç”¨ReLUåšæ¿€æ´»å‡½æ•°ï¼Ÿ[AlexNet](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)çš„3.1èŠ‚ä»å·¥ç¨‹è®­ç»ƒæ–¹é¢è§£é‡Šäº†ç”¨ReLUèƒ½å‡å°‘æ—¶é—´ä¸”ä¿è¯æ•ˆæœï¼Œ[ReLUæ¿€æ´»å‡½æ•°](http://www.cnblogs.com/neopenx/p/4453161.html)ä»ç”Ÿç‰©ç¥ç»æ–¹é¢æ¥è§£é‡Šï¼Œ[çŸ¥ä¹](https://www.zhihu.com/question/29021768)è¿™ä¸ªé—®é¢˜ä¸‹é¢çš„å›ç­”ä¹Ÿè§£é‡Šäº†ä¸ºå•¥â€œé’¦å®šâ€ReLUæ¥åšæ¿€æ´»å‡½æ•°ã€‚è¿˜æœ‰å°±æ˜¯ReLUå¯¹è§£å†³æ¢¯åº¦æ¶ˆå¤±é—®é¢˜(vanishing gradient problemï¼Œ[wiki](https://en.wikipedia.org/wiki/Vanishing_gradient_problem))çš„æ•ˆæœå¾ˆå¥½ã€‚

å½“ç„¶ï¼ŒReLUä¸æ˜¯é€‚ç”¨äºæ‰€æœ‰æ¨¡å‹çš„ã€‚å¦‚æœä½ çš„è®­ç»ƒæ•ˆæœä¸ç†æƒ³ï¼Œä¸å¦¨ä»æ¢ä¸€ä¸ªæ¿€æ´»å‡½æ•°å…¥æ‰‹ã€‚
### æ± åŒ–å±‚
#### pooling
poolingå±‚ä¹Ÿå«downsamplingå±‚ï¼Œå®ƒçš„ä½œç”¨æ˜¯ä¸¤ä¸ªï¼š
**1. å½“è¾“å…¥ä½œå‡ºå°‘é‡å¹³ç§»æ—¶ï¼Œpoolingèƒ½å¤Ÿå¸®åŠ©è¾“å…¥çš„è¡¨ç¤ºè¿‘ä¼¼ä¸å˜**
**2. ä¿ç•™ä¸»è¦ç‰¹å¾åŒæ—¶å‡å°‘å‚æ•°å’Œè®¡ç®—é‡ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œæé«˜æ¨¡å‹æ³›åèƒ½åŠ›**ã€‚
å…·ä½“å¯ä»¥å‚è€ƒ[çŸ¥ä¹](https://www.zhihu.com/question/36686900)ï¼Œæ›´åŠ è¯¦ç»†çš„å¯ä»¥çœ‹[ã€Šdeep learningã€‹](http://www.deeplearningbook.org/)çš„9.3å’Œ9.4èŠ‚ã€‚

poolingçš„å®ç°ç”±å‡ ç§æ–¹å¼ï¼Œmax poolingï¼Œaverage poolingå’ŒL2-norm poolingç­‰ï¼Œç›®å‰ä¸€èˆ¬ä½¿ç”¨max poolingï¼Œå³å–pool sizeä¸­çš„æœ€å¤§å€¼ã€‚åœ¨tensorflowä¸­çš„apiæ˜¯tf.nn.maxpoolï¼Œå®ƒçš„å‚æ•°ä¸­ksizeçš„ç¬¬äºŒã€ä¸‰ä¸ªå‚æ•°ä¸Šä¸€å±‚filterçš„å®½å’Œé«˜ã€‚

#### local response normalization
æ ¹æ®[AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)è¿™ä¸ªä¸»è¦æ˜¯ä¸ºäº†åœ¨æ•°æ®é‡è¾ƒå¤§çš„æƒ…å†µä¸‹ï¼Œé˜²æ­¢ç¥ç»å…ƒå‡ºç°é¥±å’Œâ€”â€”å³å¯¹å„ç§è¾“å…¥æ•°æ®éƒ½æ»¡è¶³ï¼Œå¢åŠ æ³›åŒ–èƒ½åŠ›ã€‚æ ¹æ®[What Is Local Response Normalization In Convolutional Neural Networks](https://prateekvjoshi.com/2016/04/05/what-is-local-response-normalization-in-convolutional-neural-networks/)ï¼Œlrnå‚è€ƒäº†ç¥ç»å­¦ä¸Šçš„ä¾§é¢æŠ‘åˆ¶(lateral inhibition)ï¼Œå¹¶ä¸”é…åˆReLUæœ‰å¥‡æ•ˆã€‚[Quora](https://www.quora.com/Why-would-a-saturated-neuron-be-a-problem)ä¸Šçš„è¿™ä¸ªå›ç­”è§£é‡Šäº†ä»€ä¹ˆæ˜¯é¥±å’Œçš„ç¥ç»å…ƒ
> We say that a neuron is saturated for these activation functions when it takes on values that are close to the boundaries of this range.

å¹¶ä¸”è¯´æ˜äº†é¥±å’Œçš„ç¥ç»å…ƒæ˜¯æ€æ ·å½±å“è®­ç»ƒçš„ã€‚

ä½†æ˜¯ï¼Œç›®å‰æœ‰è§‚ç‚¹è¯´lrnæ²¡å•¥ç”¨ï¼Œè¯·çœ‹[çŸ¥ä¹](https://www.zhihu.com/question/26871787)ï¼Œåœ¨è¿™ä¸ª[é“¾æ¥](https://books.google.com/books?id=H2c9DwAAQBAJ&pg=PA300&lpg=PA300&dq=lrn++layer+++effect&source=bl&ots=FWmNM7ULqG&sig=osAUQHWKvCE6B0Mmk3qXLu_J36c&hl=zh-CN&sa=X&ved=0ahUKEwjJ7s2zyIHYAhXI1IMKHTfXCGQQ6AEIZzAH#v=onepage&q=lrn%20%20layer%20%20%20effect&f=false)ä¸­ç»™å‡ºäº†ç§»é™¤lrnå±‚åï¼Œç²¾åº¦åªæœ‰å°äº0.1%çš„å‡å°‘ï¼Œè¿™ä¸ªå’Œå¢åŠ lrnå±‚æ‰€å¸¦æ¥çš„å¤æ‚åº¦æ¯”èµ·æ¥ï¼Œå®Œå…¨æ˜¯å¯ä»¥æ¥å—çš„ã€‚çœ‹æ¥è¦é’ˆå¯¹å…·ä½“çš„æ¨¡å‹åšå®éªŒäº†ã€‚

### å…¨è¿æ¥å±‚
#### å…¨è¿æ¥è¿ç®—
å…¨è¿æ¥(fully connected)ï¼Œå…¶å®ä»åå­—å°±å¯ä»¥çœ‹å‡ºè¿™å±‚ä¸»è¦æ˜¯æŠŠå‰é¢çš„æ‰€æœ‰è¿ç®—ç»“æœå…¨éƒ¨â€œé“¾æ¥â€åœ¨ä¸€èµ·ã€‚è¿™é‡Œæœ‰ä¸€ä¸ªå›¾æ¯”è¾ƒå½¢è±¡çš„è¡¨ç¤ºäº†è¿™ä¸ªè¿ç®—ï¼š

![å…¨è¿æ¥ç¤ºæ„å›¾](https://github.com/h312903294/MarkdownPicRep/raw/master/FCLayer%402x.png)

è¿™ä¸€å±‚çš„ç›®çš„ä¸»è¦æ˜¯å¯¹ä¹‹å‰æå–åˆ°çš„ç‰¹å¾è¿›è¡Œæ›´é«˜ä¸€çº§çš„æå–ã€‚æ¯”å¦‚ï¼Œé€šè¿‡ä¹‹å‰çš„è¿ç®—ï¼Œæˆ‘ä»¬å¾—åˆ°äº†Næ®µåœ†å¼§ï¼Œå¦‚æœè¦æœ€ç»ˆç»„æˆä¸€ä¸ªåœ†ï¼Œå°±éœ€è¦æŠŠè¿™Næ®µåœ†å¼§æ‹¼è£…åˆ°ä¸€èµ·ã€‚
å…¨è¿æ¥å±‚çš„è¾“å‡ºæ˜¯ä¸€ä¸ªNç»´çš„å‘é‡ï¼Œæœ€åä¸€å±‚çš„ç»´æ•°æ˜¯éœ€è¦åˆ†è¾¨çš„æ ‡ç­¾(label)çš„ä¸ªæ•°ï¼Œå› ä¸ºæœ€åä¼šç”¨softmaxå¯¹æœ€åä¸€ä¸ªå…¨è¿æ¥å±‚çš„è¾“å‡ºåšå½’ä¸€åŒ–ï¼Œä»¥è®¡ç®—æ¯ä¸ªæ ‡ç­¾çš„æ¦‚ç‡ï¼Œä»è€Œå¾—åˆ°è¿™ä¸€æ¬¡è®­ç»ƒçš„ç»“æœï¼Œç„¶ååŒåŸå§‹æ•°æ®æ‰€å¯¹åº”çš„æ ‡ç­¾åšæ¯”è¾ƒã€‚

åœ¨tensorflowä¸­ï¼Œtf.nn.matmulå®Œæˆå…¨è¿æ¥çš„è¿ç®—æ“ä½œï¼Œç„¶åç”¨tf.nn.reluå¯¹matmulçš„ç»“æœåšéçº¿æ€§æ•´ç†ã€‚ 
#### dropout
dropoutçš„æå‡ºæ˜¯åœ¨Hintonçš„è®ºæ–‡[Improving neural networks by preventing
co-adaptation of feature detectors](https://arxiv.org/pdf/1207.0580.pdf)ä¸­ï¼Œä»–ç”¨dropoutè§£å†³è¿‡æ‹Ÿåˆã€‚è¿™ç¯‡[blog](http://www.cnblogs.com/tornadomeet/p/3258122.html)å¯¹Hintonçš„è®ºæ–‡æœ‰ä¸€ä¸ªç®€å•çš„ç†è§£ã€‚åœ¨[AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)çš„4.2èŠ‚ä¹Ÿæœ‰è®ºè¿°ã€‚å¦æœ‰ä¸€ç¯‡[blog](http://blog.csdn.net/hjimce/article/details/50413257)æˆ‘è®¤ä¸ºè¯´çš„æ¯”è¾ƒå…¨ï¼Œä»åŸç†åˆ°å®ç°éƒ½åŸºæœ¬æ¶‰åŠåˆ°äº†ã€‚è¿˜æœ‰ä¸€ç¯‡[blog](http://blog.csdn.net/stdcoutzyx/article/details/49022443)å¯¹è®ºæ–‡çš„åˆ†æå¾ˆä¸é”™ï¼Œæˆ‘å¾ˆèµåŒç”¨æœ‰æ€§ç¹æ®–å’Œæ— æ€§ç¹æ®–æ¥ç±»æ¯”dropoutçš„ä½œç”¨ï¼Œæœ‰æ€§ç¹æ®–ä¹‹æ‰€ä»¥èƒ½é€‚åº”æ›´åŠ å¤æ‚çš„ç¯å¢ƒï¼Œæ˜¯å› ä¸ºå®ƒæ—¢èƒ½æŠŠä¼˜è‰¯åŸºå› ä¼ ä¸‹å»ï¼Œä¹Ÿèƒ½è®©æœ‰å®³åŸºå› æœ‰æ¦‚ç‡çš„ä¼ ä¸ä¸‹å»ã€‚æœ‰ä¸€å¼ å›¾è¡¨ç¤ºäº†è¿™ä¸ªè¿‡ç¨‹ï¼š
![dropout pic](https://github.com/h312903294/MarkdownPicRep/raw/master/dropout.png)
è¯¥å›¾æ¥æºäº[dropout](https://irenelizihui.files.wordpress.com/2016/02/394275.png)

åœ¨tensorflowä¸­ï¼Œä½¿ç”¨tf.nn.dropoutå®Œæˆè¯¥æ“ä½œï¼Œå®ƒçš„å‚æ•°keep_probä¸€èˆ¬è®¾ç½®0.5â€”â€”æ¥æºäºä¸Šé¢çš„Hintonçš„è®ºæ–‡ï¼Œå³æ­¤æ¬¡ä¼ é€’â€œä¸¢å¼ƒâ€ä¸€åŠçš„å…¨è¿æ¥ç»“æœã€‚è¢«â€œä¸¢å¼ƒâ€çš„éƒ¨åˆ†å¹¶æ²¡æœ‰æ¶ˆå¤±ï¼Œå®ƒä»¬çš„æƒé‡ä¹Ÿä¿ç•™ä¸‹æ¥äº†â€”â€”åªæ˜¯æš‚æ—¶ä¸æ›´æ–°ï¼Œä¸‹æ¬¡æ ·æœ¬è¾“å…¥æ—¶å®ƒä»¬å¯èƒ½åˆå¾—å·¥ä½œã€‚é‚£ä¹ˆæ¯æ¬¡è®­ç»ƒåï¼Œåªæœ‰ä¸€åŠçš„ç»“æœä¼šè¿›å…¥åˆ°åå‘ä¼ æ’­çš„å¤„ç†ä¸­ã€‚

æ€»ç»“ä¸‹ï¼Œå‰å‘ä¼ é€’åŒ…å«äº†å·ç§¯å±‚(convolution layer)ã€æ± åŒ–å±‚(pooling layer)å’Œå…¨è¿æ¥å±‚(fully connected layer)ã€‚
é€šè¿‡ä¸Šé¢çš„æ¢³ç†ï¼Œå‘ç°è¿‡æ‹Ÿåˆå¯¹äºCNNçš„è®­ç»ƒç»“æœæœ‰ç€éå¸¸å¤§çš„å½±å“ï¼Œä¼šç›´æ¥å¯¼è‡´CNNå¯¹æµ‹è¯•æ•°æ®æˆ–è€…çœŸæ˜¯æ•°æ®çš„é¢„æµ‹å‡ºç°ä¸¥é‡é—®é¢˜ï¼Œå› æ­¤éœ€è¦å¯¹è¿‡æ‹Ÿåˆè¿›è¡Œä¸€äº›é’ˆå¯¹æ€§çš„é¢„é˜²ã€‚[How can I avoid overfitting](https://www.quora.com/How-can-I-avoid-overfitting)æ˜¯Quoraä¸Šçš„æœ‰ä¸€ä¸ªç›¸å…³é—®é¢˜ï¼Œæœ€é«˜èµç»™äº†ä¸‰ä¸ªç­–ç•¥ï¼š
>1. collect more data
>2. use ensembling methods that â€œaverageâ€ models
>3. choose simpler models / penalize complexity

å¦‚æœèƒ½æ”¶é›†åˆ°æ›´å¤šçš„æ•°æ®å¹¶ä¸”æœ‰ä¸ä¹‹ç›¸é…çš„å¤„ç†èµ„æºï¼Œé‚£ä¹ˆç¬¬ä¸€ä¸ªç­–ç•¥æ˜¯æœ€å¥½çš„ã€‚
ç¬¬ä¸‰ä¸ªç­–ç•¥æ›´å¤šçš„æ˜¯å’Œå·²æœ‰æ¨¡å‹åšä¸€ä¸ªå¯¹æ¯”ï¼Œè€Œä¸”ç¬¬ä¸‰ä¸ªç­–ç•¥ä¹Ÿè¡Œä¼šå¯¼è‡´æ¬ æ‹Ÿåˆâ€”â€”å¦‚æœæ•°æ®å¤ªå°ï¼Œä¸”ç½‘ç»œå¤ªç®€å•ã€‚
é‚£ä¹ˆï¼Œå¾ˆæ˜æ˜¾ï¼Œç¬¬äºŒä¸ªç­–ç•¥å¯¹äºæˆ‘ä»¬æ¥è¯´ï¼Œæ˜¯ä¸€ä¸ªå¾ˆæœ‰æ€§ä»·æ¯”çš„ç­–ç•¥ï¼Œæœ€é«˜èµä¹Ÿæ˜¯è¿™æ ·è®¤ä¸ºçš„ã€‚ç¬¬äºŒä¸ªç­–ç•¥å®é™…ä¸Šå°±æ˜¯ä»æŠ€æœ¯ä¸Šå»å¹³å‡(average)é¢„é˜²è¿‡æ‹Ÿåˆã€‚åœ¨ä¸Šé¢æåˆ°çš„Hintonçš„è®ºæ–‡ä¸­ä¹Ÿåœ¨å¼ºè°ƒè¦
> Another way to view the dropout procedure is as a very efficient way of performing model averaging with neural networks
>A good way to reduce the error on the test set is to
average the predictions produced by a very large number of different networks
åœ¨è®ºæ–‡ä¸­ï¼Œæåˆ°äº†ä¸€ä¸ªè§‚ç‚¹â€œmean networkâ€ä¹Ÿæ˜¯å’Œâ€œaverage modelsâ€ç›¸å¯¹åº”ã€‚é‚£ä¹ˆä¸ºäº†åšåˆ°averageï¼Œæœ‰ä»¥ä¸‹å‡ ç§æ–¹æ³•ï¼ˆç”±äºç¬”è€…è‡ªå·±çš„çœ¼ç•Œé—®é¢˜ï¼Œä¸èƒ½æœé›†å®Œå…¨ï¼Œæ•¬è¯·è°…è§£ï¼‰ï¼š
**1.** æ•°æ®é›†æ‰©å±•(data augmentation)ï¼Œ
**2.** æ­£åˆ™åŒ–(Ragularization)åŒ…æ‹¬L1ã€L2(L2 Regularizationä¹Ÿå«weight decay)ï¼Œ
**3.** dropout

## æŸå¤±å‡½æ•°(loss function)
å½“è¿™ä¸ªè¿‡ç¨‹ç»“æŸåï¼Œéœ€è¦å¯¹è®­ç»ƒçš„ç»“æœè¿›è¡Œè¯„ä¼°ï¼Œè¿™ä¸ªè¯„ä¼°ä¸€èˆ¬ç”¨æŸå¤±å‡½æ•°(loss function)æ¥åšã€‚å®ƒçš„[wiki](https://en.wikipedia.org/wiki/Loss_function)ï¼Œ[çŸ¥ä¹](https://www.zhihu.com/question/52398145)å’Œ[blog](http://www.csuldw.com/2016/03/26/2016-03-26-loss-function/)ä¸¤ä¸ªè”åˆèµ·æ¥çœ‹èƒ½æ¯”è¾ƒå¥½çš„äº†è§£æŸå¤±å‡½æ•°çš„æ„æˆï¼Œå³ç”±ç»éªŒé£é™©å‡½æ•°å’Œç»“æ„é£é™©å‡½æ•°ç»„æˆï¼š

$$ \theta^* = \arg \min_\theta \frac{1}{N}{}\sum_{i=1}^{N} L(y_i, f(x_i; \theta)) + \lambda\  \Phi(\theta) $$

å¯¹äºåˆ†ç±»é—®é¢˜ï¼Œä½¿ç”¨æ¯”è¾ƒå¹¿æ³›çš„æŸå¤±å‡½æ•°æ˜¯äº¤å‰ç†µï¼Œ[çŸ¥ä¹](https://www.zhihu.com/question/41252833)æ¯”è¾ƒå¥½çš„è§£é‡Šäº†äº¤å‰ç†µã€‚è¿™é‡Œæœ‰ä¸€ç¯‡[blog](http://blog.csdn.net/marsjhao/article/details/72630147)ä»‹ç»äº†åœ¨tensorflowä¸­çš„4ä¸ªäº¤å‰ç†µç›¸å…³å‡½æ•°ã€‚

## åå‘ä¼ é€’(backward pass)
æŒ‰ç…§æˆ‘å¯¹[cs231n/optimization-2](http://cs231n.github.io/optimization-2/)çš„ç†è§£ï¼Œåå‘ä¼ é€’å…¶å®å°±æ˜¯å¯¹ç½‘ç»œè¿›è¡Œé€†åºçš„æ±‚å¯¼è¿‡ç¨‹ã€‚
>During backward pass we then successively compute (in reverse order) the corresponding variables that hold the gradients of those variables.

## æƒå€¼æ›´æ–°(weight update)
ç”¨ä¸€ä¸ªå…¬å¼è¡¨ç¤ºå³ï¼š
$$ W_n = W_{n-1} - \eta \frac{\theta E}{\theta W_{n-1}} $$
å…¶ä¸­ï¼Œ$\eta$æ˜¯learning rateï¼Œ$E$æ˜¯loss functionçš„å€¼ã€‚
[blog](http://blog.csdn.net/happyer88/article/details/46772347)åŒæ—¶ç»™å‡ºäº†åå‘ä¼ æ’­å’Œæƒå€¼æ›´æ–°çš„å…¬å¼æ¨å¯¼ï¼Œ[Back Propagation Weight Update Rule](http://www.philbrierley.com/main.html?code/bpproof.html&code/codeleft.html)ä¹Ÿåšäº†æƒå€¼æ›´æ–°çš„å…¬å¼æ¨å¯¼ã€‚

## å‚è€ƒ
[A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks](https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/)

[LayerParams](https://code.google.com/archive/p/cuda-convnet/wikis/LayerParams.wiki)

[Must Know Tips/Tricks in Deep Neural Networks (by Xiu-Shen Wei)](http://lamda.nju.edu.cn/weixs/project/CNNTricks/CNNTricks.html)

[ã€ŠDeep Learningã€‹](http://www.deeplearningbook.org/)

[Notes on Convolutional Neural Networks](http://cogprints.org/5869/1/cnn_tutorial.pdf)






