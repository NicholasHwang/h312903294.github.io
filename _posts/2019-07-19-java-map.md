---
layout: post
title: 换个角度看Java的HashMap和ConcurrentHashMap
date: 2019-07-19
author: Nicholas Huang
header-img:
categories: JAVA
tags:
    - JAVA
    - Source Code
---

# 换个角度看Java的HashMap和ConcurrentHashMap
## HashMap
我想从另外的角度来分析或者设计下hashmap——目前我看过很多的hashmap的文章都是要深入到代码级别。
如果让你造一个map的轮子，你会怎么造？
首先，我们看下map的设计需求：

>   插入，删除，查询都是O(1)或者O(logn)

有没有感觉O(1)很熟悉？平时接触的那个数据结构是O(1)?
没错，正是数组。数组由于是基于连续内存的实现，所以他可以直接使用指针（地址）来访问他的每个成员。当要访问第N个成员，那么该成员的指针（地址）就是`head+(N-1)*sizeof(element)`。这个虽然是一个四则运算的组合，会涉及多个汇编代码，但由于他的时间期望是固定的，所以是O(1)。

那么已经有数组了，为啥还要map？这个问题其实换个说法，那么已经有了自行车，还要啥汽车啊？
数组的使用有一些限制：
    
    1.只能通过下标来访问，而下标又只能是整数。如果想用string来做下标，不行
    2.数组是连续内存，就是说生成的时候就要划分一块内存。就和清初的跑马圈地一样，我先圈了就是我的，谁都不许跟我抢！这样的话，如果你实际使用比划分的小，那么就是一种浪费；如果你实际使用比划分的大，那么就要扩容，而且这种扩容还无法直接在现有的内存后面直接再划分一块，只能另起炉灶，在其他地方在划分一块更大的内存，然后把之前内存中的内容拷贝过去，最后把之前的内存释放了。这样会导致指针的变化，如果使用者没处理好，那么跑飞就是分分钟的事情。因此，STL中有一个vector来解决数组的问题。
    3.数组无法删除内容，如果你把一个数组的某个元素删除了，那么我只能说，大神牛逼。
    
所以，为了解决限制1——可能会用其他类型来做key，那么我们搞一个新的东西，map。但是限制2和3呢？这个就跟具体语言相关了。
    1. C++，使用模板来做。对于常规数据类型，STL中已有他们的compare函数。对于自定义的类型，可以通过自定义的compare函数。既然都使用compare函数来比较两个key之间的大小关系，那么实现map的结构就肯定是二叉树了。查阅STL，我们知道C++的map是红黑树，那么为什么不是AVL呢？请往下看。
    2. Java，它的一个特性是每个对象都直接或间接继承自java.lang.Object。在这个造轮子的问题中，这是一个巨大的优势，这意味着我们在父类来定一个方法生成每个类的hash值，这样就得到了一个可以比较的整数了。当然，Java也是这么实现的：

```java
    public native int hashCode()
```

但是新问题来了，Hash碰撞了怎么办？
### 解决Hash冲突
我们知道解决Hash冲突有两个方法：开放地址法和链地址法

为什么不用开放地址？我认为有这么几个原因：
    
    1.如果Hash冲突了，会导致在冲突的位置向后找一个空白位置来插入。如果数据量大，可能会退化成O(n)
    2.可能需要针对不同的数据选择不同的Hash函数，尽量避免出现冲突
    3.一般使用数组实现，大小固定，会导致无法扩容或者浪费，无法删除节点
    
为什么用链地址法？我认为有这么几个原因：
    
    1.使用数组和链表实现，兼具数组O(1)的查询和链表的动态大小，解决了上面说的限制2和3
    2.数组大小可控，冲突了就添加到每个数组元素的链表中，因此扩容的阈值就可以设置较大，并且扩容的时候只需要拷贝链表的头指针。链表对于插入和删除又非常友好。
    
因此，HashMap的数据结构是数组和链表。只是JDK1.8后，对于冲突太多导致链表过长，性能下降做了一个优化，就是链表长度大于等于8个的时候，用红黑树来替换链表。当红黑树的节点数小于等于6个，用链表替换红黑树。

为什么链表转换为红黑树的阈值是8个，根据代码的注释是和[泊松分布](https://zh.wikipedia.org/wiki/%E6%B3%8A%E6%9D%BE%E5%88%86%E4%BD%88)相关，[阿里面试题：为什么Map桶中个数超过8才转为红黑树](https://www.javazhiyin.com/34651.html)。一言以蔽之，当链表的长度为8时，要么此时数据很多，虽然hash平均分布到数组每个成员，但是每个成员的链表会变大，从而导致时间复杂度有可能退化为O(n);要么是hash函数不够平均，导致某些数组成员的链表变大。因此，根据泊松分布，链表长度为8这么小概率的事件都发生了，那么当前的情况就需要转化成树来降低时间复杂度到O(logn)

为什么不用AVL而用红黑树，[知乎的一个回单](https://www.zhihu.com/question/20545708)解释了，一言以蔽之，就是[红黑树的统计性能高于AVL](https://www.zhihu.com/question/19856999)

上面都是从设计的角度来讲，关于map的具体功能，我也先从设计的角度来讲。讲的不对或者不清楚的地方，敬请大家指正，感谢！
因为具体功能就涉及实现了，这里选择Java来讲，C++后续有空补上。
### 扩容
扩容一定是触发了某个前提条件才会发生的，这是容器类对象的普遍做法，不管是Java还是C++，都是一样的。

根据上面的分析，我们知道Java中map是一个数组，因此，它的扩容就只能是再重新分配一块更大的内存，然后把老数组的元素都拷贝过去。得益于数组的每个元素都是链表，所以实际只需要比较少的拷贝步骤即可。为什么不说只需要老数组长度的拷贝步骤，是因为扩容后，存在Rehash的流程，以前在同一个链表的某些节点，可能会Rehash到另一个链表中。

```java
    int threshold;          //所能容纳的key-value对极限
    final float loadFactor; //负载因子
    transient int modCount;
    transient int size;
    
    threshold = length * loadFactor
```
扩容的触发条件：
    
    1.map的数组table为空
    2.map的size大于threshold
    
根据上面的分析，我先假设一个扩容的流程，然后再来看Java中HashMap的具体实现。
假设的流程：
    
    1.对扩容后的大小进行校验，防止过大
    2.如果老数组为空，返回新数组
    3.如果老数组不为空，则
        3.1 如果某个数组元素孑然一身，那么对这个元素的hash值和新数组长度取余，将这个元素放到取余结果对应的数组位置上
        3.2 如果某个数组元素是红黑树节点，那么对树中所有节点Rehash
        3.3 如果某个数组元素是链表，那么对链表中所有节点Rehash
    4.Rehash流程，对元素的hash和数组的长度取余，然后再放到对应的位置，要注意判断对应位置的链表是否需要转换成红黑树
以上是我假设的流程，可以对比下Java中的实际流程，发现有这么几个地方值得注意：
    
    1.取余操作，实际上是和数组长度做与操作。这也是为什么要把map的长度设为2的N次方的原因。与操作对应一条汇编指令`AND DEST,SRC`，虽然我无法给出该汇编具体的CPU指令周期，但是可以回想上学时的微机原理，与操作实际上是两个寄存器通过与门输出结果。除法操作会转换成乘法操作，因为CPU没有除法器，因此会涉及先对除数取倒数，然后进入乘法器运算。这个过程明显比与门慢。
    2.最大容量是`1<<30`，因为最高位是符号位
    3.由于是按照2倍的关系扩容，所以Rehash流程会存在一部分在原来的位置，一部分挪到新的位置。而新的位置就是现在的位置和老数组长度之和。因此，这个流程没有真的做Hash，而是做了加法，非常节约时间。

### put操作
根据上面的分析，我先假设一个put的流程，然后再来看Java中HashMap的具体实现
假设的流程：
    
    1.判断map中的数组是否为空，为空则分配相应内存，然后放到相应的位置（取余）
    2.如果发现数组相应位置有元素，则
        2.1如果是红黑树，那么插入到红黑树中
        2.2如果是链表，那么插入到链表末尾
        2.3如果在以上两个过程中，发现了相同key，则更新对应的value
    3.检查数组的大小以决定是否扩容
    
对比Java中的实现，在2.2中会多一个判断，如果达到了转换成红黑树的条件，会进行一次转换
### 总结
通过以上的一些分析，可以看出，Java中HashMap的实现是非常高效的（与操作，树与链表转换）。同时也可以看出，它并没有考虑多线程使用的情况。那么如果要改造成多线程使用，可以有哪些方法呢？
我能想到的如下：
    
    1.对数组加锁（synchronized或者lock）
    2.把对数组的操作替换成cas操作
    
参考博文：
    [java8系列之重新认识HashMap](https://tech.meituan.com/2016/06/24/java-hashmap.html)
    [上面美团的博文有图片缺失，这个没有](https://blog.csdn.net/login_sonata/article/details/76598675)
    
那么，一起来看下Java的各位大牛是如何解决的把
## ConcurrentHashMap
顾名思义，并行哈希映射表，从这个名字中我们知道了它和上面那个HashMap的区别，它是并行的。
那么它的并行是怎样实现的呢？因为我在上面提了我改造HashMap的想法，我就直接根据Java源码分析吧。

我看的高是因为我站在巨人的肩膀上！
### Put操作
我觉得有这么几点需要注意：

    1.某个bin如果为空，则用cas来执行增加新节点的操作，如果不为空，那么要加锁（synchronized)。这个其实比较好理解，因为不为空的时候，要么是链表要么是红黑树，多线程竞争同一个资源，加锁之。如果ca失败了，说明有其他线程也在操作，需要继续后面的流程，因为此时这个bin不为空了。
    2.要注意，大神们把很多赋值操作和if写在一起了，所以看代码的时候不要忘记变量在哪里赋值的。
    3.每个bin的头结点或者说位置是`(table.length-1)&hash`。
    4.如果头结点的hash值大于等于0，说明是链表。在链表中找到了同key的更新value，没找到则插入到    链表末尾。
    
### 初始化操作
通过对sizeCtl的控制，解决多线程同时初始化的问题。即通过CAS将sizeCtl设置为-1，如果其他线程发现sizeCtl为-1，则调用`Thread.yield()`
[CAS操作说明](https://zhuanlan.zhihu.com/p/34556594)
### 扩容操作
这个操作我个人认为是和HashMap最大的区别，因为在多线程下，put和get还可以用锁（比如读写锁）或者cas来做，而扩容如果加锁，会导致线程阻塞从而搞得你生不如死。以前用过双buffer来解决日志写入磁盘的问题，扩容这里也可以做，但是两个buffer之间的数据同步怎么处理？

综上，我个人认为比较重要的地方：
    
    1.双数组，当某个bin移到备份数组的时候，对该bin的头结点设置为ForwardingNode（hash值为MOVED)
    2.扩容的时机：
        2.1 数组大小超过阈值——addCount
        2.2 链表元素超过8个但是数组总个数没超过64，进行扩容而不会转换成红黑树，这个在HashMap也是一样的——tryPresize（treeifyBin）
        2.3 发现其他线程正在扩容，帮其扩容——helpTransfer
    3.扩容时有其他线B要写，B会发现要写的那个数组元素（bin)的头结点是moved，所以它会帮助扩容
    4.cas都和循环一起使用，防止cas失败后逻辑出现中断
    
**重点代码解读：**
tryPresize中的一个判断：  
       
```java
    if((sc >>> RESIZE_STAMP_SHIFT) != rs ||
        sc == rs + 1 ||
        sc == rs + MAX_RESIZERS ||
        (nt = nextTable0 == null ||
        transferIndex <= 0)
        break;
```
**第一个判断**是sc的高16位是不是rs。这个判断的依据是开始扩容的时候对sc的cas操作：

```java
    U.compareAndSwapInt(this, SIZECTL, sc, (rs << RESIZE_STAMP_SHIFT)+2))
```
    这个操作把sc的高16位设置成了rs，因此在后续扩容的处理中，sc的高16位都应该是rs，如果不是，那么就说明当前的容量已经变了，不需要执行扩容操作。至于为什么是加2而不是加1，我猜想应该是和多线程有关，具体原因还待研究
**第二个判断**是当前同位置已经有线程处理了
**第三个判断**是当前处理扩容的线程数已经达到上限了
**第四个判断**表示nextTable正在初始化，因为sc小于0
**第五个判断**表示当前数组的所有元素（bin）都分出去了
    因此，这五个判断有一个为真，扩容操作都应该停止。
    
    
resizeStamp的作用是生成一个整数，高16位是`1000 0000 0000 0000`，低16位是当前数组大小的左边0的个数，如果大小是0，那么生成的整数是`1000 0000 0010 0000`

transfer的for循环流程：
    
    1.advance默认为真，因此第一次进入循环会取得这次要处理的数组索引的最小值和当前值
    2.根据1中取得的当前值i，如果出现：
        2.1 i<0，意味着已经把所有的bin都分完了
        2.2 i>=n，意味着扩容已经结束，因为i等于transferIndex-1，扩容后transferIndex指向新数组的最右边
        2.3 i+n >= nextn，其实这个不等式简化后就上上面2.2的不等式。该不等式两边同时-n，得到i>=nextn-n，因为我们知道扩容后的nextn是2n，那么nextn-n是n，那么不等式再简化就是i>=n，是不是和2.2一样。我猜测，之所以要做这个判断，很有可能是为了解决扩容刚结束，nextTable还没赋值给table的时候。
    3.根据1中取得的当前值i，检查所对应的bin的头结点是否为空，为空则把ForwardingNode设置到头结点，如果设置成功，则开始下一个bin的检查
    4.根据1中取得的当前值i，发现所对应的bin的头结点是ForwardingNode，则开始下一个bin的检查
    5.因为2、3、4都不为true，那么就进行数据的迁移。因此，锁当前bin——这种分段锁的思想应用很多了，最容易想到的是innodb中的行锁——先判断当前bin头结点是否为ForwardingNode——这个判断我个人感觉有点类似于double-check，为了解决多线程下锁同一个bin然后重复劳动。后面转移的代码和HashMap类似了都是先区分list和tree，然后按hash&n分成两个部分，最后加到新数组那边去。
    
关于扩容的几个博客推荐：
[ConcurrentHashMap源码分析（JDK8）扩容实现机制](https://www.jianshu.com/p/487d00afe6ca)
[深入分析ConcurrentHashMap1.8的扩容实现](https://www.jianshu.com/p/f6730d5784ad)

    
[Linux 多线程 ”一写多读” 模式下的无锁设计](https://blog.csdn.net/lqt641/article/details/55058137)   
[深入理解ConcurrentHashMap](https://zhuanlan.zhihu.com/p/27149377)
[Java 8 ConcurrentHashMap源码分析](https://juejin.im/entry/59fc786d518825297f3fa968)



